{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.optim as optim\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "filename = \"./data/wine.csv\"\n",
    "df = pd.read_csv(filename)\n",
    "df = df.drop('index', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a test/train split\n",
    "train_test_split_fraction = 0.80\n",
    "split_index = int(df.shape[0] * train_test_split_fraction)\n",
    "df_train = df[:split_index]\n",
    "df_test = df[split_index:]\n",
    "\n",
    "target = pd.get_dummies(df['quality']).values # One hot encode\n",
    "target[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5197, 11)\n",
      "(1300, 11)\n",
      "(5197, 7)\n",
      "(1300, 7)\n"
     ]
    }
   ],
   "source": [
    "# Selecting the features and the target\n",
    "X_train = df_train.drop('quality', axis = 1).values\n",
    "X_test = df_test.drop('quality', axis = 1).values\n",
    "\n",
    "y_train = target[:split_index]\n",
    "y_test = target[split_index:]\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the type\n",
    "X_train = X_train.astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "y_test = y_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform into pytorch\n",
    "X_train = torch.tensor(X_train)   \n",
    "y_train = torch.tensor(y_train)   \n",
    "X_test = torch.tensor(X_test)   \n",
    "y_test = torch.tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the neural network architecture of our baseline\n",
    "nb_hidden_neurons = 200\n",
    "nb_classes = len(pd.unique(df['quality']))\n",
    "nb_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "\n",
    "    def __init__(self, nb_features):    \n",
    "        \"\"\"Here we define the layers\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer_1 = nn.Linear(nb_features,nb_hidden_neurons)  \n",
    "        self.layer_2 = nn.Linear(nb_hidden_neurons,nb_hidden_neurons) \n",
    "        self.layer_3 = nn.Linear(nb_hidden_neurons,nb_classes) \n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self,x):   #forward pass of the neural network learning process\n",
    "        \"\"\"Here we combine the layers\n",
    "        ReLU activation function for the first layers \n",
    "        Softmax activation function for the last layer\n",
    "        \"\"\"\n",
    "        \n",
    "        activation_function = nn.ReLU() \n",
    "        last_layer_activation = nn.Softmax(dim=1)\n",
    "        \n",
    "        output_first_layer = activation_function(self.layer_1(x)) \n",
    "        output_second_layer = activation_function(self.layer_2(output_first_layer)) \n",
    "        prediction = last_layer_activation(self.layer_3(output_second_layer))\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (layer_1): Linear(in_features=11, out_features=200, bias=True)\n",
       "  (layer_2): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (layer_3): Linear(in_features=200, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_nn = Network(nb_features=X_train.shape[1])\n",
    "my_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim\n",
    "# we define the criterion by which the cost is calculated, \n",
    "    #our learning rate and our optimizer, MSELoss, 0.001 and Adam, respectiely.\n",
    "criterion = nn.MSELoss()    #criterion = loss\n",
    "learning_rate = 0.001       \n",
    "optimizer = optim.Adam(my_nn.parameters(), lr=learning_rate ) #Adam optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training process\n",
    "def training(batch_size : int, nb_steps_loss_sum : int):\n",
    "    \"\"\" Train the neural network, feeding it `batch_size` at a time\n",
    "    and saving statistics every `nb_steps_loss_sum` steps.\n",
    "    \n",
    "    Arguments:\n",
    "    \n",
    "    - batch_size [int] : the number of input samples at each training step (called a batch)\n",
    "    - nb_steps_loss_sum [int] : the number of batches before saving the loss for plotting\n",
    "    \n",
    "    Returns:\n",
    "    - loss_list : [List[double]] : value of the loss every `nb_steps_loss_sum` steps\n",
    "    \"\"\"\n",
    "\n",
    "    loss_list = []\n",
    "    running_loss = 0\n",
    "    batch_nb = 0\n",
    "\n",
    "    for epoch in range(0,50): # Number of times to iterate through the complete dataset\n",
    "        for idx in range(0, X_train.shape[0], batch_size):  \n",
    "            \n",
    "            # To Get input and output\n",
    "            input_batch = X_train[idx:idx + batch_size]\n",
    "            target = y_train[idx:idx + batch_size]\n",
    "#             print(target)\n",
    "            \n",
    "            optimizer.zero_grad() # - zero gradient buffers\n",
    "            outputs =  my_nn.forward(input_batch) # - to compute the forward pass\n",
    "#             print(outputs)\n",
    "            loss = criterion(outputs,target) # - to compute the loss\n",
    "            loss.backward() # - backpropagate\n",
    "            optimizer.step() # - to do a step\n",
    "          \n",
    "            \n",
    "            # Save the loss every `running_loss_steps` batches\n",
    "            running_loss += loss.item()\n",
    "            save_loss_condition = batch_nb % nb_steps_loss_sum == (nb_steps_loss_sum - 1)\n",
    "            if save_loss_condition:    \n",
    "                loss_list.append(running_loss)\n",
    "                running_loss = 0.0\n",
    "\n",
    "\n",
    "            batch_nb+= 1\n",
    "        \n",
    "    return loss_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb_steps_loss_sum = 1\n",
    "loss = training(batch_size=30, nb_steps_loss_sum=nb_steps_loss_sum)\n",
    "\n",
    "# Plotting the loss over training\n",
    "plt.figure()\n",
    "plt.plot(range(0, len(loss)), loss)\n",
    "plt.xlabel(f\"Batches/{nb_steps_loss_sum}\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training loss\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeScore(X, y):\n",
    "    correct = 0\n",
    "    total = y.shape[0]   #we are doing prediction on all items in one shot\n",
    "    batch_size = 30   # 30 forward pass before a backward\n",
    "    with torch.no_grad():\n",
    "        # TO COMPLETE:\n",
    "    \n",
    "        # - compute the prediction of the neural network\n",
    "        output = my_nn.forward(X)  \n",
    "        # - get the max of the prediction (e.g. get the most likely class) (to do)\n",
    "        # This can be done using `torch.max`.\n",
    "        _,predicted = torch.max(output,1)    #predicted = predicted index of the max value and '_' for the max value, we could give another name to the variable (ex: a) instead of '_'...only working with tuple like this output : https://pytorch.org/docs/stable/generated/torch.max.html\n",
    "        # - get the max of the target (e.g. correct class)\n",
    "        _,target_pred = torch.max(y,1)\n",
    "\n",
    "        # - check if the prediction is correct and count it\n",
    "#             correct += (predicted == target_pred).sum().item() \n",
    "\n",
    "#         print(predicted)\n",
    "#         print(target_pred)\n",
    "\n",
    "        for idx in range(0, X.shape[0]):\n",
    "            if predicted[idx] == target_pred[idx]:\n",
    "                correct += 1\n",
    "\n",
    "        # - count every sample\n",
    "\n",
    "    accuracy = correct/total * 100\n",
    "    print(f\"Accuracy of the network on the {total} samples: {accuracy:.2f}%\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 5197 samples: 51.93%\n",
      "Accuracy of the network on the 1300 samples: 42.23%\n"
     ]
    }
   ],
   "source": [
    "computeScore(X_train, y_train)\n",
    "computeScore(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "\n",
    "    def __init__(self, nb_features, nb_hidden_neurons):    \n",
    "        \"\"\"Here we define the layers\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer_1 = nn.Linear(nb_features,nb_hidden_neurons)  \n",
    "        self.layer_2 = nn.Linear(nb_hidden_neurons,nb_hidden_neurons) \n",
    "        self.layer_last = nn.Linear(nb_hidden_neurons,nb_classes) \n",
    "        self.nb_hidden_neurons = nb_hidden_neurons\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self,x, nb_hidden_layers, activation_function):   #forward pass of the neural network learning process\n",
    "        \"\"\"Here we combine the layers\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "      \n",
    "        last_layer_activation = nn.Softmax()\n",
    "        \n",
    "        output_first_layer = activation_function(self.layer_1(x)) \n",
    "        output_hidden_layer = activation_function(self.layer_2(output_first_layer))\n",
    "        for i in range(1, nb_hidden_layers):\n",
    "            output_hidden_layer = activation_function(self.layer_2(output_hidden_layer))\n",
    "            \n",
    "        prediction = last_layer_activation(self.layer_last(output_hidden_layer))\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training process\n",
    "def training(config, checkpoint_dir=None):\n",
    "    \"\"\" Train the neural network, feeding it `batch_size` at a time\n",
    "    and saving statistics every `nb_steps_loss_sum` steps.\n",
    "    \n",
    "    Arguments:\n",
    "    \n",
    "    - batch_size [int] : the number of input samples at each training step (called a batch)\n",
    "    - nb_steps_loss_sum [int] : the number of batches before saving the loss for plotting\n",
    "    \n",
    "    Returns:\n",
    "    - loss_list : [List[double]] : value of the loss every `nb_steps_loss_sum` steps\n",
    "    \"\"\"\n",
    "    \n",
    "    nb_steps_loss_sum = 10\n",
    "    my_nn = Network(nb_features=X_train.shape[1], nb_hidden_neurons=config['hidden_neuron'])\n",
    "    loss_list = []\n",
    "    running_loss = 0\n",
    "    batch_nb = 0\n",
    "    \n",
    "    # we define the criterion by which the cost is calculated, \n",
    "        #our learning rate and our optimizer(Adam), MSELoss\n",
    "    \n",
    "    criterion = nn.MSELoss()              #criterion = loss\n",
    "    batch_size = config['batch_size']\n",
    "    learning_rate = config['lr']       \n",
    "    optimizer = optim.Adam(my_nn.parameters(), lr=learning_rate ) #Adam optimizer \n",
    "    \n",
    "\n",
    "    for epoch in range(0,config['epoch']):       # Number of times to iterate through the complete dataset\n",
    "        for idx in range(0, X_train.shape[0], batch_size):  \n",
    "            \n",
    "            # To Get input and output\n",
    "            input_batch = X_train[idx:idx + batch_size]\n",
    "            target = y_train[idx:idx + batch_size]\n",
    "#             print(target)\n",
    "            \n",
    "            optimizer.zero_grad()           # - zero gradient buffers\n",
    "            \n",
    "            y_pred =  my_nn(input_batch.float(), nb_hidden_layers = config['nb_layers'], activation_function = config['activation'] )    # - to compute the forward pass\n",
    "#             print(outputs)\n",
    "            \n",
    "            loss = criterion(y_pred,target.float())     # - to compute the loss\n",
    "            loss.backward()         # - backpropagate\n",
    "            optimizer.step()        # - to do a step\n",
    "          \n",
    "            \n",
    "            # Save the loss every `running_loss_steps` batches\n",
    "            running_loss += loss.item()\n",
    "            save_loss_condition = batch_nb % nb_steps_loss_sum == (nb_steps_loss_sum - 1)\n",
    "            if save_loss_condition:    \n",
    "                loss_list.append(running_loss)\n",
    "                running_loss = 0.0\n",
    "\n",
    "\n",
    "            batch_nb+= 1\n",
    "        \n",
    "    tune.report(mean_loss=abs(loss_list[len(loss_list)-1]))   #to take as the mean loss, the last element of the list_loss\n",
    "    #acc_train = test(X_train, y_train, config)\n",
    "    #acc_test = test(X_test, Y_test, config)\n",
    "    #tune.report(acc_train=acc_train, acc_test=acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(X,y,config, checkpoint_dir=None):\n",
    "    my_nn = Network(nb_features=X_train.shape[1], nb_hidden_neurons=config['hidden_neuron'])\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    batch_size = config['batch_size']\n",
    "    with torch.no_grad():\n",
    "        for idx in range(0, X.shape[0], batch_size):\n",
    "            \n",
    "            total +=1\n",
    "            \n",
    "            output = my_nn(X.float(), nb_hidden_layers = config['nb_layers'], activation_function = config['activation'] )\n",
    "            \n",
    "            predicted = torch.max(output, 1)\n",
    "            \n",
    "            target_pred = torch.max(y, 1)\n",
    "            \n",
    "            if predicted[1][idx] == target_pred[1][idx]:\n",
    "                correct += 1\n",
    "                \n",
    "    accuracy = correct/total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim\n",
    "import torch.nn as nn\n",
    "from ray import tune\n",
    "#!conda install -c conda-forge ray-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.3/7.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/4 CPUs, 0/0 GPUs, 0.0/2.59 GiB heap, 0.0/0.88 GiB objects<br>Result logdir: /home/abdellah/ray_results/training_2021-03-05_10-47-01<br>Number of trials: 1/12 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name          </th><th>status  </th><th>loc  </th><th>activation  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  epoch</th><th style=\"text-align: right;\">  hidden_neuron</th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  nb_layers</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_bc338_00000</td><td>RUNNING </td><td>     </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12391)\u001b[0m /home/abdellah/anaconda3/envs/pytorch/lib/python3.7/site-packages/ray/workers/default_worker.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\u001b[2m\u001b[36m(pid=12391)\u001b[0m   parser.add_argument(\n",
      "\u001b[2m\u001b[36m(pid=12391)\u001b[0m /home/abdellah/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/autograd/__init__.py:132: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729047590/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "\u001b[2m\u001b[36m(pid=12391)\u001b[0m   allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[2m\u001b[36m(pid=12411)\u001b[0m /home/abdellah/anaconda3/envs/pytorch/lib/python3.7/site-packages/ray/workers/default_worker.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\u001b[2m\u001b[36m(pid=12411)\u001b[0m   parser.add_argument(\n",
      "\u001b[2m\u001b[36m(pid=12411)\u001b[0m /home/abdellah/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/autograd/__init__.py:132: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729047590/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "\u001b[2m\u001b[36m(pid=12411)\u001b[0m   allow_unreachable=True)  # allow_unreachable flag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_bc338_00000:\n",
      "  date: 2021-03-05_10-47-30\n",
      "  done: false\n",
      "  experiment_id: c4c99cc00d2143bf9bd2df57dbadf237\n",
      "  hostname: abdellah-Latitude-E7270\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.7846741154789925\n",
      "  neg_mean_loss: -0.7846741154789925\n",
      "  node_ip: 192.168.1.21\n",
      "  pid: 12411\n",
      "  time_since_restore: 26.692108392715454\n",
      "  time_this_iter_s: 26.692108392715454\n",
      "  time_total_s: 26.692108392715454\n",
      "  timestamp: 1614937650\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc338_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.7/7.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4/4 CPUs, 0/0 GPUs, 0.0/2.59 GiB heap, 0.0/0.88 GiB objects<br>Result logdir: /home/abdellah/ray_results/training_2021-03-05_10-47-01<br>Number of trials: 3/12 (1 PENDING, 2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name          </th><th>status  </th><th>loc               </th><th>activation  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  epoch</th><th style=\"text-align: right;\">  hidden_neuron</th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  nb_layers</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_bc338_00000</td><td>RUNNING </td><td>192.168.1.21:12411</td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.784674</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.6921</td><td style=\"text-align: right;\">      -0.784674</td></tr>\n",
       "<tr><td>training_bc338_00001</td><td>RUNNING </td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_bc338_00002</td><td>PENDING </td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-05 10:47:30,503\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'activation': SiLU()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_bc338_00000:\n",
      "  date: 2021-03-05_10-47-30\n",
      "  done: true\n",
      "  experiment_id: c4c99cc00d2143bf9bd2df57dbadf237\n",
      "  experiment_tag: 0_activation=SiLU(),batch_size=30,epoch=50,hidden_neuron=100,lr=0.001,nb_layers=2\n",
      "  hostname: abdellah-Latitude-E7270\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.7846741154789925\n",
      "  neg_mean_loss: -0.7846741154789925\n",
      "  node_ip: 192.168.1.21\n",
      "  pid: 12411\n",
      "  time_since_restore: 26.692108392715454\n",
      "  time_this_iter_s: 26.692108392715454\n",
      "  time_total_s: 26.692108392715454\n",
      "  timestamp: 1614937650\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc338_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-05 10:47:33,200\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'activation': ReLU()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_bc338_00001:\n",
      "  date: 2021-03-05_10-47-33\n",
      "  done: false\n",
      "  experiment_id: 128fa072e9d3419f8904e582f75e273b\n",
      "  hostname: abdellah-Latitude-E7270\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.77602469176054\n",
      "  neg_mean_loss: -0.77602469176054\n",
      "  node_ip: 192.168.1.21\n",
      "  pid: 12391\n",
      "  time_since_restore: 29.627844095230103\n",
      "  time_this_iter_s: 29.627844095230103\n",
      "  time_total_s: 29.627844095230103\n",
      "  timestamp: 1614937653\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc338_00001\n",
      "  \n",
      "Result for training_bc338_00001:\n",
      "  date: 2021-03-05_10-47-33\n",
      "  done: true\n",
      "  experiment_id: 128fa072e9d3419f8904e582f75e273b\n",
      "  experiment_tag: 1_activation=ReLU(),batch_size=30,epoch=50,hidden_neuron=100,lr=0.001,nb_layers=2\n",
      "  hostname: abdellah-Latitude-E7270\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.77602469176054\n",
      "  neg_mean_loss: -0.77602469176054\n",
      "  node_ip: 192.168.1.21\n",
      "  pid: 12391\n",
      "  time_since_restore: 29.627844095230103\n",
      "  time_this_iter_s: 29.627844095230103\n",
      "  time_total_s: 29.627844095230103\n",
      "  timestamp: 1614937653\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc338_00001\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12534)\u001b[0m /home/abdellah/anaconda3/envs/pytorch/lib/python3.7/site-packages/ray/workers/default_worker.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\u001b[2m\u001b[36m(pid=12534)\u001b[0m   parser.add_argument(\n",
      "\u001b[2m\u001b[36m(pid=12534)\u001b[0m /home/abdellah/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/autograd/__init__.py:132: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729047590/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "\u001b[2m\u001b[36m(pid=12534)\u001b[0m   allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[2m\u001b[36m(pid=12559)\u001b[0m /home/abdellah/anaconda3/envs/pytorch/lib/python3.7/site-packages/ray/workers/default_worker.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\u001b[2m\u001b[36m(pid=12559)\u001b[0m   parser.add_argument(\n",
      "\u001b[2m\u001b[36m(pid=12559)\u001b[0m /home/abdellah/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/autograd/__init__.py:132: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729047590/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "\u001b[2m\u001b[36m(pid=12559)\u001b[0m   allow_unreachable=True)  # allow_unreachable flag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_bc338_00002:\n",
      "  date: 2021-03-05_10-48-15\n",
      "  done: false\n",
      "  experiment_id: d3d099a44b374078b78c4f1377ce9726\n",
      "  hostname: abdellah-Latitude-E7270\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.7828299924731255\n",
      "  neg_mean_loss: -0.7828299924731255\n",
      "  node_ip: 192.168.1.21\n",
      "  pid: 12534\n",
      "  time_since_restore: 41.208709478378296\n",
      "  time_this_iter_s: 41.208709478378296\n",
      "  time_total_s: 41.208709478378296\n",
      "  timestamp: 1614937695\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc338_00002\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.7/7.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4/4 CPUs, 0/0 GPUs, 0.0/2.59 GiB heap, 0.0/0.88 GiB objects<br>Result logdir: /home/abdellah/ray_results/training_2021-03-05_10-47-01<br>Number of trials: 5/12 (1 PENDING, 2 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name          </th><th>status    </th><th>loc               </th><th>activation  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  epoch</th><th style=\"text-align: right;\">  hidden_neuron</th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  nb_layers</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_bc338_00002</td><td>RUNNING   </td><td>192.168.1.21:12534</td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.78283 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         41.2087</td><td style=\"text-align: right;\">      -0.78283 </td></tr>\n",
       "<tr><td>training_bc338_00003</td><td>RUNNING   </td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_bc338_00004</td><td>PENDING   </td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_bc338_00000</td><td>TERMINATED</td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.784674</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.6921</td><td style=\"text-align: right;\">      -0.784674</td></tr>\n",
       "<tr><td>training_bc338_00001</td><td>TERMINATED</td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.776025</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         29.6278</td><td style=\"text-align: right;\">      -0.776025</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-05 10:48:15,261\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'activation': SiLU()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_bc338_00002:\n",
      "  date: 2021-03-05_10-48-15\n",
      "  done: true\n",
      "  experiment_id: d3d099a44b374078b78c4f1377ce9726\n",
      "  experiment_tag: 2_activation=SiLU(),batch_size=30,epoch=50,hidden_neuron=200,lr=0.001,nb_layers=2\n",
      "  hostname: abdellah-Latitude-E7270\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.7828299924731255\n",
      "  neg_mean_loss: -0.7828299924731255\n",
      "  node_ip: 192.168.1.21\n",
      "  pid: 12534\n",
      "  time_since_restore: 41.208709478378296\n",
      "  time_this_iter_s: 41.208709478378296\n",
      "  time_total_s: 41.208709478378296\n",
      "  timestamp: 1614937695\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc338_00002\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12554)\u001b[0m /home/abdellah/anaconda3/envs/pytorch/lib/python3.7/site-packages/ray/workers/default_worker.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\u001b[2m\u001b[36m(pid=12554)\u001b[0m   parser.add_argument(\n",
      "\u001b[2m\u001b[36m(pid=12554)\u001b[0m /home/abdellah/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/autograd/__init__.py:132: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729047590/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "\u001b[2m\u001b[36m(pid=12554)\u001b[0m   allow_unreachable=True)  # allow_unreachable flag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_bc338_00003:\n",
      "  date: 2021-03-05_10-48-24\n",
      "  done: false\n",
      "  experiment_id: 356c8409c2ee4537a2fe73a932aa3dea\n",
      "  hostname: abdellah-Latitude-E7270\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.7963929250836372\n",
      "  neg_mean_loss: -0.7963929250836372\n",
      "  node_ip: 192.168.1.21\n",
      "  pid: 12559\n",
      "  time_since_restore: 47.25187087059021\n",
      "  time_this_iter_s: 47.25187087059021\n",
      "  time_total_s: 47.25187087059021\n",
      "  timestamp: 1614937704\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc338_00003\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.7/7.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4/4 CPUs, 0/0 GPUs, 0.0/2.59 GiB heap, 0.0/0.88 GiB objects<br>Result logdir: /home/abdellah/ray_results/training_2021-03-05_10-47-01<br>Number of trials: 6/12 (1 PENDING, 2 RUNNING, 3 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name          </th><th>status    </th><th>loc               </th><th>activation  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  epoch</th><th style=\"text-align: right;\">  hidden_neuron</th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  nb_layers</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_bc338_00003</td><td>RUNNING   </td><td>192.168.1.21:12559</td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.796393</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         47.2519</td><td style=\"text-align: right;\">      -0.796393</td></tr>\n",
       "<tr><td>training_bc338_00004</td><td>RUNNING   </td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_bc338_00005</td><td>PENDING   </td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_bc338_00000</td><td>TERMINATED</td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.784674</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.6921</td><td style=\"text-align: right;\">      -0.784674</td></tr>\n",
       "<tr><td>training_bc338_00001</td><td>TERMINATED</td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.776025</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         29.6278</td><td style=\"text-align: right;\">      -0.776025</td></tr>\n",
       "<tr><td>training_bc338_00002</td><td>TERMINATED</td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.78283 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         41.2087</td><td style=\"text-align: right;\">      -0.78283 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-05 10:48:24,592\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'activation': ReLU()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_bc338_00003:\n",
      "  date: 2021-03-05_10-48-24\n",
      "  done: true\n",
      "  experiment_id: 356c8409c2ee4537a2fe73a932aa3dea\n",
      "  experiment_tag: 3_activation=ReLU(),batch_size=30,epoch=50,hidden_neuron=200,lr=0.001,nb_layers=2\n",
      "  hostname: abdellah-Latitude-E7270\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.7963929250836372\n",
      "  neg_mean_loss: -0.7963929250836372\n",
      "  node_ip: 192.168.1.21\n",
      "  pid: 12559\n",
      "  time_since_restore: 47.25187087059021\n",
      "  time_this_iter_s: 47.25187087059021\n",
      "  time_total_s: 47.25187087059021\n",
      "  timestamp: 1614937704\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc338_00003\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12609)\u001b[0m /home/abdellah/anaconda3/envs/pytorch/lib/python3.7/site-packages/ray/workers/default_worker.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\u001b[2m\u001b[36m(pid=12609)\u001b[0m   parser.add_argument(\n",
      "\u001b[2m\u001b[36m(pid=12609)\u001b[0m /home/abdellah/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/autograd/__init__.py:132: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729047590/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "\u001b[2m\u001b[36m(pid=12609)\u001b[0m   allow_unreachable=True)  # allow_unreachable flag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_bc338_00004:\n",
      "  date: 2021-03-05_10-49-01\n",
      "  done: false\n",
      "  experiment_id: a68d82618a394eefaafd3528e007fd33\n",
      "  hostname: abdellah-Latitude-E7270\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.8379068523645401\n",
      "  neg_mean_loss: -0.8379068523645401\n",
      "  node_ip: 192.168.1.21\n",
      "  pid: 12554\n",
      "  time_since_restore: 43.28405714035034\n",
      "  time_this_iter_s: 43.28405714035034\n",
      "  time_total_s: 43.28405714035034\n",
      "  timestamp: 1614937741\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc338_00004\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.5/7.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4/4 CPUs, 0/0 GPUs, 0.0/2.59 GiB heap, 0.0/0.88 GiB objects<br>Result logdir: /home/abdellah/ray_results/training_2021-03-05_10-47-01<br>Number of trials: 7/12 (1 PENDING, 2 RUNNING, 4 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name          </th><th>status    </th><th>loc               </th><th>activation  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  epoch</th><th style=\"text-align: right;\">  hidden_neuron</th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  nb_layers</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_bc338_00004</td><td>RUNNING   </td><td>192.168.1.21:12554</td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">0.837907</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         43.2841</td><td style=\"text-align: right;\">      -0.837907</td></tr>\n",
       "<tr><td>training_bc338_00005</td><td>RUNNING   </td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_bc338_00006</td><td>PENDING   </td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_bc338_00000</td><td>TERMINATED</td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.784674</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.6921</td><td style=\"text-align: right;\">      -0.784674</td></tr>\n",
       "<tr><td>training_bc338_00001</td><td>TERMINATED</td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.776025</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         29.6278</td><td style=\"text-align: right;\">      -0.776025</td></tr>\n",
       "<tr><td>training_bc338_00002</td><td>TERMINATED</td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.78283 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         41.2087</td><td style=\"text-align: right;\">      -0.78283 </td></tr>\n",
       "<tr><td>training_bc338_00003</td><td>TERMINATED</td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.796393</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         47.2519</td><td style=\"text-align: right;\">      -0.796393</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-05 10:49:01,187\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'activation': SiLU()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_bc338_00004:\n",
      "  date: 2021-03-05_10-49-01\n",
      "  done: true\n",
      "  experiment_id: a68d82618a394eefaafd3528e007fd33\n",
      "  experiment_tag: 4_activation=SiLU(),batch_size=30,epoch=50,hidden_neuron=100,lr=0.001,nb_layers=5\n",
      "  hostname: abdellah-Latitude-E7270\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.8379068523645401\n",
      "  neg_mean_loss: -0.8379068523645401\n",
      "  node_ip: 192.168.1.21\n",
      "  pid: 12554\n",
      "  time_since_restore: 43.28405714035034\n",
      "  time_this_iter_s: 43.28405714035034\n",
      "  time_total_s: 43.28405714035034\n",
      "  timestamp: 1614937741\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc338_00004\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12645)\u001b[0m /home/abdellah/anaconda3/envs/pytorch/lib/python3.7/site-packages/ray/workers/default_worker.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\u001b[2m\u001b[36m(pid=12645)\u001b[0m   parser.add_argument(\n",
      "\u001b[2m\u001b[36m(pid=12645)\u001b[0m /home/abdellah/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/autograd/__init__.py:132: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729047590/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "\u001b[2m\u001b[36m(pid=12645)\u001b[0m   allow_unreachable=True)  # allow_unreachable flag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_bc338_00005:\n",
      "  date: 2021-03-05_10-49-12\n",
      "  done: false\n",
      "  experiment_id: 4a24dccb103b4882b1243a1b0d258cfa\n",
      "  hostname: abdellah-Latitude-E7270\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.8234105184674263\n",
      "  neg_mean_loss: -0.8234105184674263\n",
      "  node_ip: 192.168.1.21\n",
      "  pid: 12609\n",
      "  time_since_restore: 44.94474172592163\n",
      "  time_this_iter_s: 44.94474172592163\n",
      "  time_total_s: 44.94474172592163\n",
      "  timestamp: 1614937752\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc338_00005\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.6/7.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4/4 CPUs, 0/0 GPUs, 0.0/2.59 GiB heap, 0.0/0.88 GiB objects<br>Result logdir: /home/abdellah/ray_results/training_2021-03-05_10-47-01<br>Number of trials: 8/12 (1 PENDING, 2 RUNNING, 5 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name          </th><th>status    </th><th>loc               </th><th>activation  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  epoch</th><th style=\"text-align: right;\">  hidden_neuron</th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  nb_layers</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_bc338_00005</td><td>RUNNING   </td><td>192.168.1.21:12609</td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">0.823411</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         44.9447</td><td style=\"text-align: right;\">      -0.823411</td></tr>\n",
       "<tr><td>training_bc338_00006</td><td>RUNNING   </td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_bc338_00007</td><td>PENDING   </td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_bc338_00000</td><td>TERMINATED</td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.784674</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.6921</td><td style=\"text-align: right;\">      -0.784674</td></tr>\n",
       "<tr><td>training_bc338_00001</td><td>TERMINATED</td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.776025</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         29.6278</td><td style=\"text-align: right;\">      -0.776025</td></tr>\n",
       "<tr><td>training_bc338_00002</td><td>TERMINATED</td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.78283 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         41.2087</td><td style=\"text-align: right;\">      -0.78283 </td></tr>\n",
       "<tr><td>training_bc338_00003</td><td>TERMINATED</td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.796393</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         47.2519</td><td style=\"text-align: right;\">      -0.796393</td></tr>\n",
       "<tr><td>training_bc338_00004</td><td>TERMINATED</td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">0.837907</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         43.2841</td><td style=\"text-align: right;\">      -0.837907</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-05 10:49:12,145\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'activation': ReLU()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_bc338_00005:\n",
      "  date: 2021-03-05_10-49-12\n",
      "  done: true\n",
      "  experiment_id: 4a24dccb103b4882b1243a1b0d258cfa\n",
      "  experiment_tag: 5_activation=ReLU(),batch_size=30,epoch=50,hidden_neuron=100,lr=0.001,nb_layers=5\n",
      "  hostname: abdellah-Latitude-E7270\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.8234105184674263\n",
      "  neg_mean_loss: -0.8234105184674263\n",
      "  node_ip: 192.168.1.21\n",
      "  pid: 12609\n",
      "  time_since_restore: 44.94474172592163\n",
      "  time_this_iter_s: 44.94474172592163\n",
      "  time_total_s: 44.94474172592163\n",
      "  timestamp: 1614937752\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc338_00005\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12670)\u001b[0m /home/abdellah/anaconda3/envs/pytorch/lib/python3.7/site-packages/ray/workers/default_worker.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\u001b[2m\u001b[36m(pid=12670)\u001b[0m   parser.add_argument(\n",
      "\u001b[2m\u001b[36m(pid=12670)\u001b[0m /home/abdellah/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/autograd/__init__.py:132: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729047590/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "\u001b[2m\u001b[36m(pid=12670)\u001b[0m   allow_unreachable=True)  # allow_unreachable flag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_bc338_00006:\n",
      "  date: 2021-03-05_10-50-02\n",
      "  done: false\n",
      "  experiment_id: a1e9fa33faa94cfb8f7012c87987a140\n",
      "  hostname: abdellah-Latitude-E7270\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.8313305750489235\n",
      "  neg_mean_loss: -0.8313305750489235\n",
      "  node_ip: 192.168.1.21\n",
      "  pid: 12645\n",
      "  time_since_restore: 58.71076250076294\n",
      "  time_this_iter_s: 58.71076250076294\n",
      "  time_total_s: 58.71076250076294\n",
      "  timestamp: 1614937802\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc338_00006\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.6/7.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4/4 CPUs, 0/0 GPUs, 0.0/2.59 GiB heap, 0.0/0.88 GiB objects<br>Result logdir: /home/abdellah/ray_results/training_2021-03-05_10-47-01<br>Number of trials: 9/12 (1 PENDING, 2 RUNNING, 6 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name          </th><th>status    </th><th>loc               </th><th>activation  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  epoch</th><th style=\"text-align: right;\">  hidden_neuron</th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  nb_layers</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_bc338_00006</td><td>RUNNING   </td><td>192.168.1.21:12645</td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">0.831331</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         58.7108</td><td style=\"text-align: right;\">      -0.831331</td></tr>\n",
       "<tr><td>training_bc338_00007</td><td>RUNNING   </td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_bc338_00008</td><td>PENDING   </td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_bc338_00000</td><td>TERMINATED</td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.784674</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.6921</td><td style=\"text-align: right;\">      -0.784674</td></tr>\n",
       "<tr><td>training_bc338_00001</td><td>TERMINATED</td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.776025</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         29.6278</td><td style=\"text-align: right;\">      -0.776025</td></tr>\n",
       "<tr><td>training_bc338_00002</td><td>TERMINATED</td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.78283 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         41.2087</td><td style=\"text-align: right;\">      -0.78283 </td></tr>\n",
       "<tr><td>training_bc338_00003</td><td>TERMINATED</td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.796393</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         47.2519</td><td style=\"text-align: right;\">      -0.796393</td></tr>\n",
       "<tr><td>training_bc338_00004</td><td>TERMINATED</td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">0.837907</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         43.2841</td><td style=\"text-align: right;\">      -0.837907</td></tr>\n",
       "<tr><td>training_bc338_00005</td><td>TERMINATED</td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">0.823411</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         44.9447</td><td style=\"text-align: right;\">      -0.823411</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-05 10:50:02,853\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'activation': SiLU()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_bc338_00006:\n",
      "  date: 2021-03-05_10-50-02\n",
      "  done: true\n",
      "  experiment_id: a1e9fa33faa94cfb8f7012c87987a140\n",
      "  experiment_tag: 6_activation=SiLU(),batch_size=30,epoch=50,hidden_neuron=200,lr=0.001,nb_layers=5\n",
      "  hostname: abdellah-Latitude-E7270\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.8313305750489235\n",
      "  neg_mean_loss: -0.8313305750489235\n",
      "  node_ip: 192.168.1.21\n",
      "  pid: 12645\n",
      "  time_since_restore: 58.71076250076294\n",
      "  time_this_iter_s: 58.71076250076294\n",
      "  time_total_s: 58.71076250076294\n",
      "  timestamp: 1614937802\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc338_00006\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12709)\u001b[0m /home/abdellah/anaconda3/envs/pytorch/lib/python3.7/site-packages/ray/workers/default_worker.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\u001b[2m\u001b[36m(pid=12709)\u001b[0m   parser.add_argument(\n",
      "\u001b[2m\u001b[36m(pid=12709)\u001b[0m /home/abdellah/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/autograd/__init__.py:132: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729047590/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "\u001b[2m\u001b[36m(pid=12709)\u001b[0m   allow_unreachable=True)  # allow_unreachable flag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_bc338_00007:\n",
      "  date: 2021-03-05_10-50-24\n",
      "  done: false\n",
      "  experiment_id: 013f93c9bc9941b99a76a63a77f8ffce\n",
      "  hostname: abdellah-Latitude-E7270\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.8444036841392517\n",
      "  neg_mean_loss: -0.8444036841392517\n",
      "  node_ip: 192.168.1.21\n",
      "  pid: 12670\n",
      "  time_since_restore: 69.33388566970825\n",
      "  time_this_iter_s: 69.33388566970825\n",
      "  time_total_s: 69.33388566970825\n",
      "  timestamp: 1614937824\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc338_00007\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.8/7.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4/4 CPUs, 0/0 GPUs, 0.0/2.59 GiB heap, 0.0/0.88 GiB objects<br>Result logdir: /home/abdellah/ray_results/training_2021-03-05_10-47-01<br>Number of trials: 10/12 (1 PENDING, 2 RUNNING, 7 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name          </th><th>status    </th><th>loc               </th><th>activation  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  epoch</th><th style=\"text-align: right;\">  hidden_neuron</th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  nb_layers</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_bc338_00007</td><td>RUNNING   </td><td>192.168.1.21:12670</td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">0.844404</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         69.3339</td><td style=\"text-align: right;\">      -0.844404</td></tr>\n",
       "<tr><td>training_bc338_00008</td><td>RUNNING   </td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_bc338_00009</td><td>PENDING   </td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_bc338_00000</td><td>TERMINATED</td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.784674</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.6921</td><td style=\"text-align: right;\">      -0.784674</td></tr>\n",
       "<tr><td>training_bc338_00001</td><td>TERMINATED</td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.776025</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         29.6278</td><td style=\"text-align: right;\">      -0.776025</td></tr>\n",
       "<tr><td>training_bc338_00002</td><td>TERMINATED</td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.78283 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         41.2087</td><td style=\"text-align: right;\">      -0.78283 </td></tr>\n",
       "<tr><td>training_bc338_00003</td><td>TERMINATED</td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.796393</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         47.2519</td><td style=\"text-align: right;\">      -0.796393</td></tr>\n",
       "<tr><td>training_bc338_00004</td><td>TERMINATED</td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">0.837907</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         43.2841</td><td style=\"text-align: right;\">      -0.837907</td></tr>\n",
       "<tr><td>training_bc338_00005</td><td>TERMINATED</td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">0.823411</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         44.9447</td><td style=\"text-align: right;\">      -0.823411</td></tr>\n",
       "<tr><td>training_bc338_00006</td><td>TERMINATED</td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">0.831331</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         58.7108</td><td style=\"text-align: right;\">      -0.831331</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-05 10:50:24,158\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'activation': ReLU()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_bc338_00007:\n",
      "  date: 2021-03-05_10-50-24\n",
      "  done: true\n",
      "  experiment_id: 013f93c9bc9941b99a76a63a77f8ffce\n",
      "  experiment_tag: 7_activation=ReLU(),batch_size=30,epoch=50,hidden_neuron=200,lr=0.001,nb_layers=5\n",
      "  hostname: abdellah-Latitude-E7270\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.8444036841392517\n",
      "  neg_mean_loss: -0.8444036841392517\n",
      "  node_ip: 192.168.1.21\n",
      "  pid: 12670\n",
      "  time_since_restore: 69.33388566970825\n",
      "  time_this_iter_s: 69.33388566970825\n",
      "  time_total_s: 69.33388566970825\n",
      "  timestamp: 1614937824\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc338_00007\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12733)\u001b[0m /home/abdellah/anaconda3/envs/pytorch/lib/python3.7/site-packages/ray/workers/default_worker.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\u001b[2m\u001b[36m(pid=12733)\u001b[0m   parser.add_argument(\n",
      "\u001b[2m\u001b[36m(pid=12733)\u001b[0m /home/abdellah/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/autograd/__init__.py:132: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729047590/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "\u001b[2m\u001b[36m(pid=12733)\u001b[0m   allow_unreachable=True)  # allow_unreachable flag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_bc338_00008:\n",
      "  date: 2021-03-05_10-51-01\n",
      "  done: false\n",
      "  experiment_id: dfcdfc7093274dc0a3c01167d36eff59\n",
      "  hostname: abdellah-Latitude-E7270\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.9627626314759254\n",
      "  neg_mean_loss: -0.9627626314759254\n",
      "  node_ip: 192.168.1.21\n",
      "  pid: 12709\n",
      "  time_since_restore: 56.0509307384491\n",
      "  time_this_iter_s: 56.0509307384491\n",
      "  time_total_s: 56.0509307384491\n",
      "  timestamp: 1614937861\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc338_00008\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.7/7.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4/4 CPUs, 0/0 GPUs, 0.0/2.59 GiB heap, 0.0/0.88 GiB objects<br>Result logdir: /home/abdellah/ray_results/training_2021-03-05_10-47-01<br>Number of trials: 11/12 (1 PENDING, 2 RUNNING, 8 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name          </th><th>status    </th><th>loc               </th><th>activation  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  epoch</th><th style=\"text-align: right;\">  hidden_neuron</th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  nb_layers</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_bc338_00008</td><td>RUNNING   </td><td>192.168.1.21:12709</td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">0.962763</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         56.0509</td><td style=\"text-align: right;\">      -0.962763</td></tr>\n",
       "<tr><td>training_bc338_00009</td><td>RUNNING   </td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_bc338_00010</td><td>PENDING   </td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_bc338_00000</td><td>TERMINATED</td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.784674</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.6921</td><td style=\"text-align: right;\">      -0.784674</td></tr>\n",
       "<tr><td>training_bc338_00001</td><td>TERMINATED</td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.776025</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         29.6278</td><td style=\"text-align: right;\">      -0.776025</td></tr>\n",
       "<tr><td>training_bc338_00002</td><td>TERMINATED</td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.78283 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         41.2087</td><td style=\"text-align: right;\">      -0.78283 </td></tr>\n",
       "<tr><td>training_bc338_00003</td><td>TERMINATED</td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.796393</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         47.2519</td><td style=\"text-align: right;\">      -0.796393</td></tr>\n",
       "<tr><td>training_bc338_00004</td><td>TERMINATED</td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">0.837907</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         43.2841</td><td style=\"text-align: right;\">      -0.837907</td></tr>\n",
       "<tr><td>training_bc338_00005</td><td>TERMINATED</td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">0.823411</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         44.9447</td><td style=\"text-align: right;\">      -0.823411</td></tr>\n",
       "<tr><td>training_bc338_00006</td><td>TERMINATED</td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">0.831331</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         58.7108</td><td style=\"text-align: right;\">      -0.831331</td></tr>\n",
       "<tr><td>training_bc338_00007</td><td>TERMINATED</td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">0.844404</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         69.3339</td><td style=\"text-align: right;\">      -0.844404</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-05 10:51:01,506\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'activation': SiLU()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_bc338_00008:\n",
      "  date: 2021-03-05_10-51-01\n",
      "  done: true\n",
      "  experiment_id: dfcdfc7093274dc0a3c01167d36eff59\n",
      "  experiment_tag: 8_activation=SiLU(),batch_size=30,epoch=50,hidden_neuron=100,lr=0.001,nb_layers=10\n",
      "  hostname: abdellah-Latitude-E7270\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.9627626314759254\n",
      "  neg_mean_loss: -0.9627626314759254\n",
      "  node_ip: 192.168.1.21\n",
      "  pid: 12709\n",
      "  time_since_restore: 56.0509307384491\n",
      "  time_this_iter_s: 56.0509307384491\n",
      "  time_total_s: 56.0509307384491\n",
      "  timestamp: 1614937861\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc338_00008\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12769)\u001b[0m /home/abdellah/anaconda3/envs/pytorch/lib/python3.7/site-packages/ray/workers/default_worker.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\u001b[2m\u001b[36m(pid=12769)\u001b[0m   parser.add_argument(\n",
      "\u001b[2m\u001b[36m(pid=12769)\u001b[0m /home/abdellah/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/autograd/__init__.py:132: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729047590/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "\u001b[2m\u001b[36m(pid=12769)\u001b[0m   allow_unreachable=True)  # allow_unreachable flag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_bc338_00009:\n",
      "  date: 2021-03-05_10-51-17\n",
      "  done: false\n",
      "  experiment_id: 746a358939cf4f388e954ee2c9ff05c8\n",
      "  hostname: abdellah-Latitude-E7270\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.9270795360207558\n",
      "  neg_mean_loss: -0.9270795360207558\n",
      "  node_ip: 192.168.1.21\n",
      "  pid: 12733\n",
      "  time_since_restore: 50.387184381484985\n",
      "  time_this_iter_s: 50.387184381484985\n",
      "  time_total_s: 50.387184381484985\n",
      "  timestamp: 1614937877\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc338_00009\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.4/7.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4/4 CPUs, 0/0 GPUs, 0.0/2.59 GiB heap, 0.0/0.88 GiB objects<br>Result logdir: /home/abdellah/ray_results/training_2021-03-05_10-47-01<br>Number of trials: 12/12 (1 PENDING, 2 RUNNING, 9 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name          </th><th>status    </th><th>loc               </th><th>activation  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  epoch</th><th style=\"text-align: right;\">  hidden_neuron</th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  nb_layers</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_bc338_00009</td><td>RUNNING   </td><td>192.168.1.21:12733</td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">0.92708 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         50.3872</td><td style=\"text-align: right;\">      -0.92708 </td></tr>\n",
       "<tr><td>training_bc338_00010</td><td>RUNNING   </td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_bc338_00011</td><td>PENDING   </td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_bc338_00000</td><td>TERMINATED</td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.784674</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.6921</td><td style=\"text-align: right;\">      -0.784674</td></tr>\n",
       "<tr><td>training_bc338_00001</td><td>TERMINATED</td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.776025</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         29.6278</td><td style=\"text-align: right;\">      -0.776025</td></tr>\n",
       "<tr><td>training_bc338_00002</td><td>TERMINATED</td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.78283 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         41.2087</td><td style=\"text-align: right;\">      -0.78283 </td></tr>\n",
       "<tr><td>training_bc338_00003</td><td>TERMINATED</td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.796393</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         47.2519</td><td style=\"text-align: right;\">      -0.796393</td></tr>\n",
       "<tr><td>training_bc338_00004</td><td>TERMINATED</td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">0.837907</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         43.2841</td><td style=\"text-align: right;\">      -0.837907</td></tr>\n",
       "<tr><td>training_bc338_00005</td><td>TERMINATED</td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">0.823411</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         44.9447</td><td style=\"text-align: right;\">      -0.823411</td></tr>\n",
       "<tr><td>training_bc338_00006</td><td>TERMINATED</td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">0.831331</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         58.7108</td><td style=\"text-align: right;\">      -0.831331</td></tr>\n",
       "<tr><td>training_bc338_00007</td><td>TERMINATED</td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">0.844404</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         69.3339</td><td style=\"text-align: right;\">      -0.844404</td></tr>\n",
       "<tr><td>training_bc338_00008</td><td>TERMINATED</td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">0.962763</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         56.0509</td><td style=\"text-align: right;\">      -0.962763</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-05 10:51:17,603\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'activation': ReLU()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_bc338_00009:\n",
      "  date: 2021-03-05_10-51-17\n",
      "  done: true\n",
      "  experiment_id: 746a358939cf4f388e954ee2c9ff05c8\n",
      "  experiment_tag: 9_activation=ReLU(),batch_size=30,epoch=50,hidden_neuron=100,lr=0.001,nb_layers=10\n",
      "  hostname: abdellah-Latitude-E7270\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.9270795360207558\n",
      "  neg_mean_loss: -0.9270795360207558\n",
      "  node_ip: 192.168.1.21\n",
      "  pid: 12733\n",
      "  time_since_restore: 50.387184381484985\n",
      "  time_this_iter_s: 50.387184381484985\n",
      "  time_total_s: 50.387184381484985\n",
      "  timestamp: 1614937877\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc338_00009\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12794)\u001b[0m /home/abdellah/anaconda3/envs/pytorch/lib/python3.7/site-packages/ray/workers/default_worker.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\u001b[2m\u001b[36m(pid=12794)\u001b[0m   parser.add_argument(\n",
      "\u001b[2m\u001b[36m(pid=12794)\u001b[0m /home/abdellah/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/autograd/__init__.py:132: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729047590/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "\u001b[2m\u001b[36m(pid=12794)\u001b[0m   allow_unreachable=True)  # allow_unreachable flag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_bc338_00010:\n",
      "  date: 2021-03-05_10-52-49\n",
      "  done: false\n",
      "  experiment_id: 560c40a3c8f14cc9a85b6ec0ac81f063\n",
      "  hostname: abdellah-Latitude-E7270\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 2.8476191759109497\n",
      "  neg_mean_loss: -2.8476191759109497\n",
      "  node_ip: 192.168.1.21\n",
      "  pid: 12769\n",
      "  time_since_restore: 105.84605026245117\n",
      "  time_this_iter_s: 105.84605026245117\n",
      "  time_total_s: 105.84605026245117\n",
      "  timestamp: 1614937969\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc338_00010\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.8/7.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4/4 CPUs, 0/0 GPUs, 0.0/2.59 GiB heap, 0.0/0.88 GiB objects<br>Result logdir: /home/abdellah/ray_results/training_2021-03-05_10-47-01<br>Number of trials: 12/12 (2 RUNNING, 10 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name          </th><th>status    </th><th>loc               </th><th>activation  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  epoch</th><th style=\"text-align: right;\">  hidden_neuron</th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  nb_layers</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_bc338_00010</td><td>RUNNING   </td><td>192.168.1.21:12769</td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">2.84762 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        105.846 </td><td style=\"text-align: right;\">      -2.84762 </td></tr>\n",
       "<tr><td>training_bc338_00011</td><td>RUNNING   </td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td></tr>\n",
       "<tr><td>training_bc338_00000</td><td>TERMINATED</td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.784674</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.6921</td><td style=\"text-align: right;\">      -0.784674</td></tr>\n",
       "<tr><td>training_bc338_00001</td><td>TERMINATED</td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.776025</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         29.6278</td><td style=\"text-align: right;\">      -0.776025</td></tr>\n",
       "<tr><td>training_bc338_00002</td><td>TERMINATED</td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.78283 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         41.2087</td><td style=\"text-align: right;\">      -0.78283 </td></tr>\n",
       "<tr><td>training_bc338_00003</td><td>TERMINATED</td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.796393</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         47.2519</td><td style=\"text-align: right;\">      -0.796393</td></tr>\n",
       "<tr><td>training_bc338_00004</td><td>TERMINATED</td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">0.837907</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         43.2841</td><td style=\"text-align: right;\">      -0.837907</td></tr>\n",
       "<tr><td>training_bc338_00005</td><td>TERMINATED</td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">0.823411</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         44.9447</td><td style=\"text-align: right;\">      -0.823411</td></tr>\n",
       "<tr><td>training_bc338_00006</td><td>TERMINATED</td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">0.831331</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         58.7108</td><td style=\"text-align: right;\">      -0.831331</td></tr>\n",
       "<tr><td>training_bc338_00007</td><td>TERMINATED</td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">0.844404</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         69.3339</td><td style=\"text-align: right;\">      -0.844404</td></tr>\n",
       "<tr><td>training_bc338_00008</td><td>TERMINATED</td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">0.962763</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         56.0509</td><td style=\"text-align: right;\">      -0.962763</td></tr>\n",
       "<tr><td>training_bc338_00009</td><td>TERMINATED</td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">0.92708 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         50.3872</td><td style=\"text-align: right;\">      -0.92708 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-05 10:52:49,693\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'activation': SiLU()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_bc338_00010:\n",
      "  date: 2021-03-05_10-52-49\n",
      "  done: true\n",
      "  experiment_id: 560c40a3c8f14cc9a85b6ec0ac81f063\n",
      "  experiment_tag: 10_activation=SiLU(),batch_size=30,epoch=50,hidden_neuron=200,lr=0.001,nb_layers=10\n",
      "  hostname: abdellah-Latitude-E7270\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 2.8476191759109497\n",
      "  neg_mean_loss: -2.8476191759109497\n",
      "  node_ip: 192.168.1.21\n",
      "  pid: 12769\n",
      "  time_since_restore: 105.84605026245117\n",
      "  time_this_iter_s: 105.84605026245117\n",
      "  time_total_s: 105.84605026245117\n",
      "  timestamp: 1614937969\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc338_00010\n",
      "  \n",
      "Result for training_bc338_00011:\n",
      "  date: 2021-03-05_10-52-56\n",
      "  done: false\n",
      "  experiment_id: 38431b143a964fe4bc607fc38f2cb5ce\n",
      "  hostname: abdellah-Latitude-E7270\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.914558470249176\n",
      "  neg_mean_loss: -0.914558470249176\n",
      "  node_ip: 192.168.1.21\n",
      "  pid: 12794\n",
      "  time_since_restore: 96.11981010437012\n",
      "  time_this_iter_s: 96.11981010437012\n",
      "  time_total_s: 96.11981010437012\n",
      "  timestamp: 1614937976\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc338_00011\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.2/7.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2/4 CPUs, 0/0 GPUs, 0.0/2.59 GiB heap, 0.0/0.88 GiB objects<br>Result logdir: /home/abdellah/ray_results/training_2021-03-05_10-47-01<br>Number of trials: 12/12 (1 RUNNING, 11 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name          </th><th>status    </th><th>loc               </th><th>activation  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  epoch</th><th style=\"text-align: right;\">  hidden_neuron</th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  nb_layers</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_bc338_00011</td><td>RUNNING   </td><td>192.168.1.21:12794</td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">0.914558</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         96.1198</td><td style=\"text-align: right;\">      -0.914558</td></tr>\n",
       "<tr><td>training_bc338_00000</td><td>TERMINATED</td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.784674</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.6921</td><td style=\"text-align: right;\">      -0.784674</td></tr>\n",
       "<tr><td>training_bc338_00001</td><td>TERMINATED</td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.776025</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         29.6278</td><td style=\"text-align: right;\">      -0.776025</td></tr>\n",
       "<tr><td>training_bc338_00002</td><td>TERMINATED</td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.78283 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         41.2087</td><td style=\"text-align: right;\">      -0.78283 </td></tr>\n",
       "<tr><td>training_bc338_00003</td><td>TERMINATED</td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.796393</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         47.2519</td><td style=\"text-align: right;\">      -0.796393</td></tr>\n",
       "<tr><td>training_bc338_00004</td><td>TERMINATED</td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">0.837907</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         43.2841</td><td style=\"text-align: right;\">      -0.837907</td></tr>\n",
       "<tr><td>training_bc338_00005</td><td>TERMINATED</td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">0.823411</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         44.9447</td><td style=\"text-align: right;\">      -0.823411</td></tr>\n",
       "<tr><td>training_bc338_00006</td><td>TERMINATED</td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">0.831331</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         58.7108</td><td style=\"text-align: right;\">      -0.831331</td></tr>\n",
       "<tr><td>training_bc338_00007</td><td>TERMINATED</td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">0.844404</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         69.3339</td><td style=\"text-align: right;\">      -0.844404</td></tr>\n",
       "<tr><td>training_bc338_00008</td><td>TERMINATED</td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">0.962763</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         56.0509</td><td style=\"text-align: right;\">      -0.962763</td></tr>\n",
       "<tr><td>training_bc338_00009</td><td>TERMINATED</td><td>                  </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">0.92708 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         50.3872</td><td style=\"text-align: right;\">      -0.92708 </td></tr>\n",
       "<tr><td>training_bc338_00010</td><td>TERMINATED</td><td>                  </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">2.84762 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        105.846 </td><td style=\"text-align: right;\">      -2.84762 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-05 10:52:56,534\tINFO logger.py:690 -- Removed the following hyperparameter values when logging to tensorboard: {'activation': ReLU()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for training_bc338_00011:\n",
      "  date: 2021-03-05_10-52-56\n",
      "  done: true\n",
      "  experiment_id: 38431b143a964fe4bc607fc38f2cb5ce\n",
      "  experiment_tag: 11_activation=ReLU(),batch_size=30,epoch=50,hidden_neuron=200,lr=0.001,nb_layers=10\n",
      "  hostname: abdellah-Latitude-E7270\n",
      "  iterations_since_restore: 1\n",
      "  mean_loss: 0.914558470249176\n",
      "  neg_mean_loss: -0.914558470249176\n",
      "  node_ip: 192.168.1.21\n",
      "  pid: 12794\n",
      "  time_since_restore: 96.11981010437012\n",
      "  time_this_iter_s: 96.11981010437012\n",
      "  time_total_s: 96.11981010437012\n",
      "  timestamp: 1614937976\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: bc338_00011\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.2/7.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/4 CPUs, 0/0 GPUs, 0.0/2.59 GiB heap, 0.0/0.88 GiB objects<br>Result logdir: /home/abdellah/ray_results/training_2021-03-05_10-47-01<br>Number of trials: 12/12 (12 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name          </th><th>status    </th><th>loc  </th><th>activation  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  epoch</th><th style=\"text-align: right;\">  hidden_neuron</th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  nb_layers</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_bc338_00000</td><td>TERMINATED</td><td>     </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.784674</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.6921</td><td style=\"text-align: right;\">      -0.784674</td></tr>\n",
       "<tr><td>training_bc338_00001</td><td>TERMINATED</td><td>     </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.776025</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         29.6278</td><td style=\"text-align: right;\">      -0.776025</td></tr>\n",
       "<tr><td>training_bc338_00002</td><td>TERMINATED</td><td>     </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.78283 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         41.2087</td><td style=\"text-align: right;\">      -0.78283 </td></tr>\n",
       "<tr><td>training_bc338_00003</td><td>TERMINATED</td><td>     </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">0.796393</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         47.2519</td><td style=\"text-align: right;\">      -0.796393</td></tr>\n",
       "<tr><td>training_bc338_00004</td><td>TERMINATED</td><td>     </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">0.837907</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         43.2841</td><td style=\"text-align: right;\">      -0.837907</td></tr>\n",
       "<tr><td>training_bc338_00005</td><td>TERMINATED</td><td>     </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">0.823411</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         44.9447</td><td style=\"text-align: right;\">      -0.823411</td></tr>\n",
       "<tr><td>training_bc338_00006</td><td>TERMINATED</td><td>     </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">0.831331</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         58.7108</td><td style=\"text-align: right;\">      -0.831331</td></tr>\n",
       "<tr><td>training_bc338_00007</td><td>TERMINATED</td><td>     </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">0.844404</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         69.3339</td><td style=\"text-align: right;\">      -0.844404</td></tr>\n",
       "<tr><td>training_bc338_00008</td><td>TERMINATED</td><td>     </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">0.962763</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         56.0509</td><td style=\"text-align: right;\">      -0.962763</td></tr>\n",
       "<tr><td>training_bc338_00009</td><td>TERMINATED</td><td>     </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            100</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">0.92708 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         50.3872</td><td style=\"text-align: right;\">      -0.92708 </td></tr>\n",
       "<tr><td>training_bc338_00010</td><td>TERMINATED</td><td>     </td><td>SiLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">2.84762 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        105.846 </td><td style=\"text-align: right;\">      -2.84762 </td></tr>\n",
       "<tr><td>training_bc338_00011</td><td>TERMINATED</td><td>     </td><td>ReLU()      </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">0.914558</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         96.1198</td><td style=\"text-align: right;\">      -0.914558</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-05 10:52:56,590\tINFO tune.py:450 -- Total run time: 355.01 seconds (354.94 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "search_space = {\n",
    "    'lr': tune.grid_search([0.001]),\n",
    "    'hidden_neuron': tune.grid_search([ 100, 200]),\n",
    "    'epoch' : tune.grid_search([ 50]),\n",
    "    'batch_size': tune.grid_search([30]),\n",
    "    'nb_layers': tune.grid_search([2,5,10]),\n",
    "    'activation': tune.grid_search([nn.SiLU(), nn.ReLU()])\n",
    "    \n",
    "}\n",
    "analysis = tune.run(training, config=search_space, resources_per_trial={\"cpu\": 2}, mode = 'min' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
